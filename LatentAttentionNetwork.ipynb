{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "dcf4a415ca83291c7f1c53e2c047d1b4fa16418cbb17c8d1d496605e4de4e2d5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from ResidualAttentionNetwork import ResidualAttentionNetwork\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Conv2DTranspose, Flatten, Reshape, Attention\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import optimizers,Sequential\n",
    "from keras.models import Model\n",
    "import keras\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(cuda_only=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH=128\n",
    "IMAGE_HEIGHT=128\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    validation_split=.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 3868 images belonging to 4 classes.\nFound 1657 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir=\"./nerthus-dataset-frames/\"\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.3) # set validation split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir, # same directory as training data\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation') # set as validation data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "latent_size=64\n",
    "\n",
    "loss_fn1 = keras.losses.MeanSquaredError()\n",
    "loss_fn2 = keras.losses.CategoricalCrossentropy()\n",
    "optimizer=optimizers.Adam(lr=0.01)\n",
    "# Prepare the metrics.\n",
    "train_acc_metric1 = keras.metrics.MeanSquaredError()\n",
    "val_acc_metric1 = keras.metrics.MeanSquaredError()\n",
    "train_acc_metric2 = keras.metrics.CategoricalAccuracy()\n",
    "val_acc_metric2 = keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "input_img = Input(shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))  \n",
    "# You can experiment with the encoder layers, i.e. add or change them\n",
    "x = Conv2D(16, (3, 3), activation='relu', strides=2, padding='same')(input_img)\n",
    "x = Conv2D(32, (3, 3), activation='relu', strides=2, padding='same')(x)    \n",
    "encoded_shape = x.shape\n",
    "x = Flatten()(x)\n",
    "encoded = Dense(latent_size)(x)\n",
    "encoderModel = Model(input_img,encoded,name='encoder')\n",
    "\n",
    "encoded_input = Input(shape=(latent_size,))\n",
    "x = Dense(np.prod(encoded_shape[1:]))(encoded_input)\n",
    "x = Reshape((encoded_shape[1], encoded_shape[2], encoded_shape[3]))(x)\n",
    "x = Conv2DTranspose(32,(3, 3), activation='relu',strides=2, padding='same')(x)\n",
    "x = Conv2DTranspose(16,(3, 3), activation='relu', strides=2, padding='same')(x)\n",
    "outputDecoder = Conv2DTranspose(3,(3, 3), activation='sigmoid', padding='same')(x)\n",
    "decoderModel = Model(encoded_input,outputDecoder,name='decoder')\n",
    "autoencoder = Model(input_img, decoderModel(encoderModel(input_img)),name=\"autoencoder\")\n",
    "# autoencoder.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "\n",
    "inputLayer = Input(shape=(latent_size,))\n",
    "encoded_input1=tf.expand_dims(inputLayer,2)\n",
    "encoded_input1=tf.matmul(encoded_input1, tf.transpose(encoded_input1,perm=[0,2,1]))\n",
    "encoded=tf.expand_dims(encoded_input1,3)\n",
    "# encoded_input1.shape\n",
    "output=ResidualAttentionNetwork((latent_size, encoded.shape[2], 1), 4, activation='softmax').build_model_for_latent_input(encoded)\n",
    "classificationModel = Model(inputs=inputLayer, outputs=output,name=\"classification\")\n",
    "\n",
    "# classificationModel.compile(optimizer=optimizer,\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n"
   ]
  },
  {
   "source": [
    "# Train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]\n",
      "Start of epoch 0\n",
      "  1%|          | 2/200 [00:00<01:58,  1.68it/s]Training loss (for one batch) at step 0: 0.0967\n",
      "Seen so far: 64 samples\n",
      " 26%|██▌       | 52/200 [00:06<00:16,  9.09it/s]Training loss (for one batch) at step 50: 0.0594\n",
      "Seen so far: 3264 samples\n",
      " 51%|█████     | 102/200 [00:12<00:11,  8.85it/s]Training loss (for one batch) at step 100: 0.0377\n",
      "Seen so far: 6464 samples\n",
      " 76%|███████▌  | 152/200 [00:17<00:05,  8.87it/s]Training loss (for one batch) at step 150: 0.0457\n",
      "Seen so far: 9664 samples\n",
      "100%|██████████| 200/200 [00:23<00:00,  8.59it/s]\n",
      "Training acc over epoch: 0.0575\n",
      "  0%|          | 1/200 [00:00<00:21,  9.37it/s]Validation acc: 0.0433\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 0.0409\n",
      "Seen so far: 64 samples\n",
      " 26%|██▌       | 52/200 [00:05<00:16,  9.00it/s]Training loss (for one batch) at step 50: 0.0459\n",
      "Seen so far: 3264 samples\n",
      " 51%|█████     | 102/200 [00:11<00:10,  8.96it/s]Training loss (for one batch) at step 100: 0.0418\n",
      "Seen so far: 6464 samples\n",
      " 76%|███████▌  | 152/200 [00:17<00:05,  8.66it/s]Training loss (for one batch) at step 150: 0.0327\n",
      "Seen so far: 9664 samples\n",
      "100%|██████████| 200/200 [00:22<00:00,  8.84it/s]\n",
      "Training acc over epoch: 0.0369\n",
      "  0%|          | 1/200 [00:00<00:22,  8.72it/s]Validation acc: 0.0297\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 0.0269\n",
      "Seen so far: 64 samples\n",
      " 26%|██▌       | 52/200 [00:05<00:16,  8.74it/s]Training loss (for one batch) at step 50: 0.0242\n",
      "Seen so far: 3264 samples\n",
      " 51%|█████     | 102/200 [00:11<00:11,  8.61it/s]Training loss (for one batch) at step 100: 0.0238\n",
      "Seen so far: 6464 samples\n",
      " 76%|███████▌  | 152/200 [00:17<00:05,  8.76it/s]Training loss (for one batch) at step 150: 0.0191\n",
      "Seen so far: 9664 samples\n",
      "100%|██████████| 200/200 [00:23<00:00,  8.69it/s]\n",
      "Training acc over epoch: 0.0220\n",
      "  0%|          | 1/200 [00:00<00:27,  7.21it/s]Validation acc: 0.0176\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one batch) at step 0: 0.0160\n",
      "Seen so far: 64 samples\n",
      " 26%|██▌       | 52/200 [00:05<00:16,  9.10it/s]Training loss (for one batch) at step 50: 0.0138\n",
      "Seen so far: 3264 samples\n",
      " 51%|█████     | 102/200 [00:11<00:11,  8.74it/s]Training loss (for one batch) at step 100: 0.0146\n",
      "Seen so far: 6464 samples\n",
      " 76%|███████▌  | 152/200 [00:17<00:05,  8.65it/s]Training loss (for one batch) at step 150: 0.0132\n",
      "Seen so far: 9664 samples\n",
      "100%|██████████| 200/200 [00:22<00:00,  8.75it/s]\n",
      "Training acc over epoch: 0.0152\n",
      "  0%|          | 1/200 [00:00<00:22,  8.72it/s]Validation acc: 0.0145\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one batch) at step 0: 0.0142\n",
      "Seen so far: 64 samples\n",
      " 26%|██▌       | 52/200 [00:06<00:16,  8.92it/s]Training loss (for one batch) at step 50: 0.0100\n",
      "Seen so far: 3264 samples\n",
      " 51%|█████     | 102/200 [00:11<00:11,  8.32it/s]Training loss (for one batch) at step 100: 0.0142\n",
      "Seen so far: 6464 samples\n",
      " 76%|███████▌  | 152/200 [00:17<00:05,  8.94it/s]Training loss (for one batch) at step 150: 0.0117\n",
      "Seen so far: 9664 samples\n",
      "100%|██████████| 200/200 [00:22<00:00,  8.71it/s]\n",
      "Training acc over epoch: 0.0125\n",
      "  0%|          | 1/200 [00:00<00:21,  9.12it/s]Validation acc: 0.0121\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one batch) at step 0: 0.0117\n",
      "Seen so far: 64 samples\n",
      " 26%|██▌       | 52/200 [00:06<00:18,  7.97it/s]Training loss (for one batch) at step 50: 0.0079\n",
      "Seen so far: 3264 samples\n",
      " 51%|█████     | 102/200 [00:11<00:12,  8.07it/s]Training loss (for one batch) at step 100: 0.0120\n",
      "Seen so far: 6464 samples\n",
      " 76%|███████▌  | 152/200 [00:17<00:05,  8.91it/s]Training loss (for one batch) at step 150: 0.0109\n",
      "Seen so far: 9664 samples\n",
      "100%|██████████| 200/200 [00:22<00:00,  8.77it/s]\n",
      "Training acc over epoch: 0.0110\n",
      "  0%|          | 1/200 [00:00<00:24,  8.02it/s]Validation acc: 0.0112\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one batch) at step 0: 0.0112\n",
      "Seen so far: 64 samples\n",
      " 26%|██▌       | 52/200 [00:06<00:18,  7.95it/s]Training loss (for one batch) at step 50: 0.0104\n",
      "Seen so far: 3264 samples\n",
      " 51%|█████     | 102/200 [00:12<00:10,  8.93it/s]Training loss (for one batch) at step 100: 0.0083\n",
      "Seen so far: 6464 samples\n",
      " 76%|███████▌  | 152/200 [00:18<00:05,  8.48it/s]Training loss (for one batch) at step 150: 0.0125\n",
      "Seen so far: 9664 samples\n",
      "100%|██████████| 200/200 [00:23<00:00,  8.44it/s]\n",
      "Training acc over epoch: 0.0098\n",
      "  0%|          | 1/200 [00:00<00:21,  9.11it/s]Validation acc: 0.0105\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one batch) at step 0: 0.0095\n",
      "Seen so far: 64 samples\n",
      " 26%|██▋       | 53/200 [00:05<00:15,  9.52it/s]Training loss (for one batch) at step 50: 0.0083\n",
      "Seen so far: 3264 samples\n",
      " 51%|█████     | 102/200 [00:11<00:10,  9.01it/s]Training loss (for one batch) at step 100: 0.0073\n",
      "Seen so far: 6464 samples\n",
      " 76%|███████▌  | 152/200 [00:16<00:05,  8.85it/s]Training loss (for one batch) at step 150: 0.0077\n",
      "Seen so far: 9664 samples\n",
      "100%|██████████| 200/200 [00:22<00:00,  8.99it/s]\n",
      "Training acc over epoch: 0.0091\n",
      "  0%|          | 1/200 [00:00<00:21,  9.37it/s]Validation acc: 0.0100\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one batch) at step 0: 0.0094\n",
      "Seen so far: 64 samples\n",
      " 26%|██▌       | 52/200 [00:05<00:16,  9.03it/s]Training loss (for one batch) at step 50: 0.0081\n",
      "Seen so far: 3264 samples\n",
      " 51%|█████     | 102/200 [00:11<00:11,  8.57it/s]Training loss (for one batch) at step 100: 0.0075\n",
      "Seen so far: 6464 samples\n",
      " 76%|███████▌  | 152/200 [00:17<00:05,  9.04it/s]Training loss (for one batch) at step 150: 0.0090\n",
      "Seen so far: 9664 samples\n",
      "100%|██████████| 200/200 [00:22<00:00,  8.88it/s]\n",
      "Training acc over epoch: 0.0086\n",
      "  0%|          | 1/200 [00:00<00:21,  9.12it/s]Validation acc: 0.0092\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one batch) at step 0: 0.0078\n",
      "Seen so far: 64 samples\n",
      " 26%|██▌       | 52/200 [00:06<00:18,  7.88it/s]Training loss (for one batch) at step 50: 0.0077\n",
      "Seen so far: 3264 samples\n",
      " 51%|█████     | 102/200 [00:11<00:11,  8.71it/s]Training loss (for one batch) at step 100: 0.0104\n",
      "Seen so far: 6464 samples\n",
      " 76%|███████▌  | 152/200 [00:17<00:05,  8.87it/s]Training loss (for one batch) at step 150: 0.0080\n",
      "Seen so far: 9664 samples\n",
      "100%|██████████| 200/200 [00:22<00:00,  8.71it/s]\n",
      "Training acc over epoch: 0.0079\n",
      "Validation acc: 0.0090\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nb_epochs=10\n",
    "\n",
    "@tf.function\n",
    "def train_step(x):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = autoencoder(x, training=True)\n",
    "        loss_value = loss_fn1(x, logits)\n",
    "    grads = tape.gradient(loss_value, autoencoder.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, autoencoder.trainable_weights))\n",
    "    train_acc_metric1.update_state(x, logits)\n",
    "    return loss_value\n",
    "\n",
    "@tf.function\n",
    "def test_step(x):\n",
    "    val_logits = autoencoder(x, training=False)\n",
    "    val_acc_metric1.update_state(x, val_logits)\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    for step in tqdm(range(200)):\n",
    "\n",
    "        (x_batch_train, y_batch_train)=next(train_generator)\n",
    "        loss_value = train_step(x_batch_train)\n",
    "\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric1.result()\n",
    "    print(\"Training mse over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric1.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for indexVal in range(20):\n",
    "        x_batch_val, y_batch_val=next(validation_generator)\n",
    "        test_step(x_batch_val)\n",
    "\n",
    "    val_acc = val_acc_metric1.result()\n",
    "    val_acc_metric1.reset_states()\n",
    "    print(\"Validation mse: %.4f\" % (float(val_acc),))\n",
    "   \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]\n",
      "Start of epoch 0\n",
      "100%|██████████| 200/200 [02:31<00:00,  1.32it/s]\n",
      "Training acc over epoch: 0.4148\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]Validation acc: 0.4750\n",
      "\n",
      "Start of epoch 1\n",
      "100%|██████████| 200/200 [02:22<00:00,  1.40it/s]\n",
      "Training acc over epoch: 0.4931\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]Validation acc: 0.4510\n",
      "\n",
      "Start of epoch 2\n",
      "100%|██████████| 200/200 [02:22<00:00,  1.41it/s]\n",
      "Training acc over epoch: 0.5019\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]Validation acc: 0.4688\n",
      "\n",
      "Start of epoch 3\n",
      "100%|██████████| 200/200 [02:20<00:00,  1.42it/s]\n",
      "Training acc over epoch: 0.4869\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]Validation acc: 0.1813\n",
      "\n",
      "Start of epoch 4\n",
      "100%|██████████| 200/200 [02:21<00:00,  1.42it/s]\n",
      "Training acc over epoch: 0.4762\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]Validation acc: 0.5250\n",
      "\n",
      "Start of epoch 5\n",
      "100%|██████████| 200/200 [02:22<00:00,  1.40it/s]\n",
      "Training acc over epoch: 0.4975\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]Validation acc: 0.5063\n",
      "\n",
      "Start of epoch 6\n",
      "100%|██████████| 200/200 [02:24<00:00,  1.38it/s]\n",
      "Training acc over epoch: 0.4869\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]Validation acc: 0.5312\n",
      "\n",
      "Start of epoch 7\n",
      "100%|██████████| 200/200 [02:21<00:00,  1.41it/s]\n",
      "Training acc over epoch: 0.4937\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]Validation acc: 0.5375\n",
      "\n",
      "Start of epoch 8\n",
      "100%|██████████| 200/200 [02:17<00:00,  1.45it/s]\n",
      "Training acc over epoch: 0.5000\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]Validation acc: 0.4750\n",
      "\n",
      "Start of epoch 9\n",
      "100%|██████████| 200/200 [02:17<00:00,  1.45it/s]\n",
      "Training acc over epoch: 0.4724\n",
      "Validation acc: 0.3938\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nb_epochs=10\n",
    "\n",
    "@tf.function\n",
    "def train_step(x,y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = classificationModel(x, training=True)\n",
    "        loss_value = loss_fn2(y, logits)\n",
    "    grads = tape.gradient(loss_value, classificationModel.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, classificationModel.trainable_weights))\n",
    "    train_acc_metric2.update_state(y, logits)\n",
    "    return loss_value\n",
    "\n",
    "@tf.function\n",
    "def test_step(x,y):\n",
    "    val_logits = classificationModel(x, training=False)\n",
    "    val_acc_metric2.update_state(y, val_logits)\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    for step in tqdm(range(200)):\n",
    "\n",
    "        (x_batch_train, y_batch_train)=next(train_generator)\n",
    "        x_batch_train=encoderModel(x_batch_train)\n",
    "        loss_value = train_step(x_batch_train,y_batch_train)\n",
    "\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric2.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric2.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for indexVal in range(20):\n",
    "        x_batch_val, y_batch_val=next(validation_generator)\n",
    "        x_batch_val=encoderModel(x_batch_val)\n",
    "        test_step(x_batch_val,y_batch_val)\n",
    "\n",
    "    val_acc = val_acc_metric2.result()\n",
    "    val_acc_metric2.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "   \n",
    "        \n",
    "    "
   ]
  }
 ]
}